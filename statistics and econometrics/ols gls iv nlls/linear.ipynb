{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models\n",
    "\n",
    "*Monday 20, September*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `statsmodels` package\n",
    "\n",
    "_`statsmodels` is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration._\n",
    "\n",
    "The online documentation is hosted at [statsmodels.org](https://www.statsmodels.org/stable/index.html)\n",
    "\n",
    "It covered:\n",
    "\n",
    "- Linear Regression \n",
    "- Generalized Linear Models \n",
    "- Generalized Estimating Equations \n",
    "- Generalized Additive Models (GAM) \n",
    "- Robust Linear Models \n",
    "- Linear Mixed Effects Models \n",
    "- Regression with Discrete Dependent Variable \n",
    "- Generalized Linear Mixed Effects Models \n",
    "- ANOVA \n",
    "- Time Series analysis `tsa` \n",
    "- Time Series Analysis by State Space Methods statespace \n",
    "- Vector Autoregressions `tsa.vector_ar` \n",
    "- Methods for Survival and Duration Analysis \n",
    "- Statistics `stats` \n",
    "- Nonparametric Methods nonparametric \n",
    "- Generalized Method of Moments `gmm` \n",
    "- Contingency tables \n",
    "- Multiple Imputation with Chained Equations \n",
    "- Multivariate Statistics multivariate \n",
    "- Empirical Likelihood emplike \n",
    "- Other Models miscmodels \n",
    "- Distributions \n",
    "- Graphics \n",
    "- Input-Output iolib \n",
    "- Tools \n",
    "- The Datasets Package \n",
    "- Sandbox \n",
    "- Working with Large Data Sets \n",
    "- Optimization\n",
    "\n",
    "`statsmodels` works smoothly with the `pandas` in a way that DataFrame is the dataset form it supports by default.\n",
    "\n",
    "Anaconda has installed `statsmodels` module by default.\n",
    "Before using the functions and classes inside, we need to import the `statsmodels.api` and `statsmodels.formula.api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `statsmodels` is similiar to the output of functions in `R`.\n",
    "We start with the most widely used and elementary statistical methods : ordinary least square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. How to fit a dataset and see the result**\n",
    "\n",
    "We use the dataset `Guerry` provided by `statsmodel` which studied the determinants of the number of lottery sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dept',\n",
       " 'Region',\n",
       " 'Department',\n",
       " 'Crime_pers',\n",
       " 'Crime_prop',\n",
       " 'Literacy',\n",
       " 'Donations',\n",
       " 'Infants',\n",
       " 'Suicides',\n",
       " 'MainCity',\n",
       " 'Wealth',\n",
       " 'Commerce',\n",
       " 'Clergy',\n",
       " 'Crime_parents',\n",
       " 'Infanticide',\n",
       " 'Donation_clergy',\n",
       " 'Lottery',\n",
       " 'Desertion',\n",
       " 'Instruction',\n",
       " 'Prostitutes',\n",
       " 'Distance',\n",
       " 'Area',\n",
       " 'Pop1831']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "dat = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data\n",
    "# list of the variables\n",
    "list(dat.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, we studied the relationship between lottery and the literacy and population (in the log scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model (using the natural log of one of the regressors)\n",
    "model = smf.ols('Lottery ~ Literacy + np.log(Pop1831)', data=dat)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the results, we need an additional step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Lottery   R-squared:                       0.348\n",
      "Model:                            OLS   Adj. R-squared:                  0.333\n",
      "Method:                 Least Squares   F-statistic:                     22.20\n",
      "Date:                Tue, 27 Aug 2019   Prob (F-statistic):           1.90e-08\n",
      "Time:                        18:39:14   Log-Likelihood:                -379.82\n",
      "No. Observations:                  86   AIC:                             765.6\n",
      "Df Residuals:                      83   BIC:                             773.0\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept         246.4341     35.233      6.995      0.000     176.358     316.510\n",
      "Literacy           -0.4889      0.128     -3.832      0.000      -0.743      -0.235\n",
      "np.log(Pop1831)   -31.3114      5.977     -5.239      0.000     -43.199     -19.424\n",
      "==============================================================================\n",
      "Omnibus:                        3.713   Durbin-Watson:                   2.019\n",
      "Prob(Omnibus):                  0.156   Jarque-Bera (JB):                3.394\n",
      "Skew:                          -0.487   Prob(JB):                        0.183\n",
      "Kurtosis:                       3.003   Cond. No.                         702.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. When the dataset is not in `DataFrame`**\n",
    "\n",
    "The dataset above is provided by `statsmodels` package hence in the form it supports. \n",
    "However, in many situations, the dataset is not constructed yet. \n",
    "In this case, we can use `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.168\n",
      "Model:                            OLS   Adj. R-squared:                  0.151\n",
      "Method:                 Least Squares   F-statistic:                     9.796\n",
      "Date:                Tue, 27 Aug 2019   Prob (F-statistic):           0.000133\n",
      "Time:                        18:46:55   Log-Likelihood:                -16.388\n",
      "No. Observations:                 100   AIC:                             38.78\n",
      "Df Residuals:                      97   BIC:                             46.59\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5404      0.075     20.632      0.000       1.392       1.689\n",
      "x1             0.0945      0.093      1.019      0.311      -0.090       0.279\n",
      "x2             0.4613      0.106      4.358      0.000       0.251       0.671\n",
      "==============================================================================\n",
      "Omnibus:                       54.531   Durbin-Watson:                   1.815\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                7.030\n",
      "Skew:                          -0.011   Prob(JB):                       0.0297\n",
      "Kurtosis:                       1.701   Cond. No.                         5.29\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate artificial data (2 regressors + constant)\n",
    "nobs = 100\n",
    "\n",
    "X = np.random.random((nobs, 2))\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "beta = [1, .1, .5]\n",
    "\n",
    "e = np.random.random(nobs)\n",
    "\n",
    "y = np.dot(X, beta) + e\n",
    "\n",
    "# Fit regression model\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "# Inspect the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can create a dataset and make it supported by `statsmodels`.\n",
    "Details can be found here: [adding a dataset](https://www.statsmodels.org/stable/dev/dataset_notes.html?highlight=statsmodels%20datasets#adding-a-dataset-an-example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3. Wald's test**\n",
    "\n",
    "Besides the fitting, `statsmodels` also supports many statsitical testing methods.\n",
    "Here, we show how to use _Wald's test_ in `statsmodels`. \n",
    "\n",
    "Again, we consider the  dataset `Guerry`.\n",
    "\n",
    "We want to analyse the effect of _Wealth_ and _Literacy_ on the _Crime_pers_ and test:\n",
    "\n",
    "> whether the coeffcients of _Wealth_ and _Literacy_ are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=array([[0.03467668]]), p=0.8527291641569565, df_denom=83, df_num=1>\n"
     ]
    }
   ],
   "source": [
    "formula = 'Crime_pers ~ Wealth + Literacy'\n",
    "results = smf.ols(formula, dat).fit()\n",
    "hypotheses = '(Wealth = Literacy)'\n",
    "f_test = results.f_test(hypotheses)\n",
    "print(f_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
